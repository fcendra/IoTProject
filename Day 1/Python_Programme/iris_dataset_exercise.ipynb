{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore some warning messages before importing\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Gael Varoquaux\n",
    "# Modified for documentation by Jaques Grobler, Yang Han\n",
    "# License: BSD 3 clause\n",
    "\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is a classification problem\n",
    "# predict the species of an iris using the measurements\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Iris Dataset\n",
    "\n",
    "The rows are the samples, the columns are measurements (features).\n",
    "There are 4 features per sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data= iris['data'], \n",
    "    columns= iris['feature_names']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data with the input features and target output/label (iris species) side-by-side\n",
    "\n",
    "pd.DataFrame(\n",
    "    data= np.c_[iris['data'], \n",
    "                iris['target'], \n",
    "                iris['target_names'][iris['target']]\n",
    "               ],\n",
    "    columns= iris['feature_names'] + ['target', 'target_name']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Load the input features (data) from iris dataset to `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X: sepal length, sepal width, \n",
    "#    petal length, petal width\n",
    "\n",
    "### START CODE HERE ###\n",
    "X = None\n",
    "### END CODE HERE ###\n",
    "\n",
    "# show the first 5 rows, and all columns of the iris features\n",
    "X[0:5, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "array([[5.1, 3.5, 1.4, 0.2],\n",
    "       [4.9, 3. , 1.4, 0.2],\n",
    "       [4.7, 3.2, 1.3, 0.2],\n",
    "       [4.6, 3.1, 1.5, 0.2],\n",
    "       [5. , 3.6, 1.4, 0.2]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting graph later, we only consider the first 2 features (sepal length, sepal width) for now.\n",
    "\n",
    "**Exercise:** Filter out only the first 2 features for `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "# X = X[:,:2]\n",
    "### END CODE HERE ###\n",
    "\n",
    "# show the first 5 rows of X \n",
    "X[0:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "array([[5.1, 3.5],\n",
    "       [4.9, 3. ],\n",
    "       [4.7, 3.2],\n",
    "       [4.6, 3.1],\n",
    "       [5. , 3.6```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Load the target output to `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "y = None\n",
    "### END CODE HERE ###\n",
    "\n",
    "# show first 5 rows of the iris species\n",
    "# all of the 5 samples belong to target 0 (setosa)\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "array([0, 0, 0, 0, 0])```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into training data and test data. The data is divided randomly. 80% of the data goes to training dataset, 20% of the data goes to test dataset. ```random_state``` is set to fix the seed used by the random number generator for randomly dividing the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Load a LogisticRegression model from `sklearn.linear_model` to `logreg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "logreg = None\n",
    "### END CODE HERE ###\n",
    "\n",
    "logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Fit the LogisticRegression model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
    "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
    "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Use the LogisticRegression model to do prediction on the training data, and store the result in `y_predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "y_predicted = None\n",
    "### END CODE HERE ###\n",
    "\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "array([2, 2, 0, 0, 2, 1, 2, 0, 0, 1, 1, 0, 2, 2, 1, 1, 1, 1, 0, 0, 2, 0,\n",
    "       0, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 0, 0, 2, 2, 2, 2, 0, 2, 1, 1, 0,\n",
    "       2, 1, 2, 0, 2, 2, 0, 0, 1, 2, 1, 0, 0, 1, 0, 1, 2, 0, 2, 0, 0, 2,\n",
    "       0, 0, 2, 2, 2, 1, 1, 0, 0, 2, 2, 0, 0, 1, 0, 2, 2, 2, 1, 1, 2, 0,\n",
    "       0, 1, 2, 2, 2, 2, 0, 0, 0, 1, 1, 0, 2, 2, 1, 2, 2, 0, 1, 0, 1, 1,\n",
    "       1, 1, 2, 1, 1, 0, 1, 1, 2, 2])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Compute the percentage of correct predictions on training data.\n",
    "\n",
    "Hint: Use the `accuracy_score` method from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "0.7833333333333333\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Use the LogisticRegression model to do prediction on the test data, and store the result in `y_predicted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "y_predicted = None\n",
    "### END CODE HERE ###\n",
    "\n",
    "y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "array([2, 2, 2, 1, 0, 1, 2, 0, 0, 1, 2, 0, 1, 2, 2, 2, 0, 0, 1, 0, 0, 2,\n",
    "       0, 1, 0, 0, 0, 1, 2, 0])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Compute the percentage of correct predictions on test data.\n",
    "\n",
    "Hint: Use the `accuracy_score` method from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "None\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "```\n",
    "0.8333333333333334\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for each point (x1, x2)\n",
    "# where x1 in the range of sepal length\n",
    "#       x2 in the range of sepal width\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "h = .02  # step size in the mesh\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot the decision boundary\n",
    "# decision boundary partitions the two-dimensional \n",
    "# space into 3 sets, each representing for one species\n",
    "\n",
    "# we will assign a color to each point\n",
    "# in the mesh [x_min, x_max] x [y_min, y_max]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "# put the result into a color plot\n",
    "# show regions with different color\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# plot the training points (with black edges)\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train,\n",
    "            edgecolors='k', cmap=plt.cm.Paired)\n",
    "\n",
    "# plot the test points (with red edges)\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=y_test,\n",
    "            edgecolors='r', cmap=plt.cm.Paired)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving The Training Model\n",
    "\n",
    "At this point, you can try to use all of the 4 features for training, and you can get up to around **95%** accuracy! Note that because the input features will have 4 dimensions and thus cannot be plotted on a 2D or 3D graph.\n",
    "\n",
    "You can also try to set a higher `C` value for the LogisticRegression, to penalize wrongly classified data more.\n",
    "e.g. \n",
    "```\n",
    "logreg = LogisticRegression(C=1e5)\n",
    "```\n",
    "\n",
    "For more tunable parameters, visit the [official documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
